# ChaseMyCareer - Complete Requirements Document

## 1. Application Overview

### 1.1 Application Name
ChaseMyCareer

### 1.2 Application Description
A comprehensive 50-day job search acceleration platform that guides users through a structured career development program. The platform features dual-role access (User & Admin), OAuth authentication, progress tracking, application management, resume/cover letter builders, and administrative oversight capabilities.

### 1.3 Core Features
- **Authentication System**: Google OAuth, LinkedIn OAuth, Email/Password registration and login
- **User Dashboard**: 50-day progress tracker, application management, resume builder, cover letter generator
- **Admin Dashboard**: User management, participant analytics, account access, messaging system
- **Database**: Cloudflare D1 (primary) + Supabase (supplementary storage)
- **Progress Tracking**: Day-by-day curriculum with specific topics and completion status
- **Testing Suite**: Unit tests, integration tests, manual testing procedures
- **CI/CD Pipeline**: GitHub Actions automated deployment

---

## 2. Project Setup Instructions

### 2.1 Initial Project Creation

**Step 1: Create Cloudflare Workers Project**
```bash
npm create cloudflare@latest -- chasemycareer-backend
```

Setup options:
- Template: Hello World example
- Type: Worker only
- Language: TypeScript
- Git: Yes
- Deploy: No (manual deployment after configuration)

**Step 2: Create Frontend Project**
```bash
npm create vite@latest chasemycareer-frontend -- --template react-ts
cd chasemycareer-frontend
npm install
```

**Step 3: Install Additional Dependencies**

For backend:
```bash
cd chasemycareer-backend
npm install @supabase/supabase-js bcryptjs jsonwebtoken
npm install --save-dev @types/bcryptjs @types/jsonwebtoken
npm install --save-dev vitest @vitest/ui @testing-library/react @testing-library/jest-dom
npm install --save-dev supertest @types/supertest
```

For frontend:
```bash
cd chasemycareer-frontend
npm install @supabase/supabase-js react-router-dom
npm install --save-dev @types/react-router-dom
```

### 2.2 Database Setup

**Step 1: Create Cloudflare D1 Database**
```bash
cd chasemycareer-backend
npx wrangler d1 create chasemycareer-db
```

When prompted, select Yes to automatically add binding to wrangler.jsonc.

**Step 2: Create Database Schema**

Create `schema.sql` file:

```sql
-- Users Table
DROP TABLE IF EXISTS users;
CREATE TABLE users (
  id TEXT PRIMARY KEY,
  email TEXT UNIQUE NOT NULL,
  password_hash TEXT,
  full_name TEXT,
  auth_provider TEXT DEFAULT 'email',
  google_id TEXT,
  linkedin_id TEXT,
  role TEXT DEFAULT 'user',
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- User Profiles
DROP TABLE IF EXISTS user_profiles;
CREATE TABLE user_profiles (
  user_id TEXT PRIMARY KEY,
  phone TEXT,
  location TEXT,
  target_role TEXT,
  experience_level TEXT,
  preferred_industries TEXT,
  FOREIGN KEY (user_id) REFERENCES users(id)
);

-- Daily Tasks (50 Days)
DROP TABLE IF EXISTS daily_tasks;
CREATE TABLE daily_tasks (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  day_number INTEGER NOT NULL,
  topic TEXT NOT NULL,
  description TEXT,
  completed INTEGER DEFAULT 0,
  completed_at DATETIME,
  FOREIGN KEY (user_id) REFERENCES users(id)
);

-- Job Applications
DROP TABLE IF EXISTS job_applications;
CREATE TABLE job_applications (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  company_name TEXT NOT NULL,
  position_title TEXT NOT NULL,
  job_url TEXT,
  status TEXT DEFAULT 'applied',
  applied_date DATE,
  notes TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (user_id) REFERENCES users(id)
);

-- Resumes
DROP TABLE IF EXISTS resumes;
CREATE TABLE resumes (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  title TEXT NOT NULL,
  content TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (user_id) REFERENCES users(id)
);

-- Cover Letters
DROP TABLE IF EXISTS cover_letters;
CREATE TABLE cover_letters (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  title TEXT NOT NULL,
  content TEXT,
  company_name TEXT,
  position_title TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (user_id) REFERENCES users(id)
);

-- Admin Messages
DROP TABLE IF EXISTS admin_messages;
CREATE TABLE admin_messages (
  id TEXT PRIMARY KEY,
  admin_id TEXT NOT NULL,
  recipient_id TEXT,
  subject TEXT,
  message TEXT,
  sent_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (admin_id) REFERENCES users(id),
  FOREIGN KEY (recipient_id) REFERENCES users(id)
);

-- User Sessions
DROP TABLE IF EXISTS user_sessions;
CREATE TABLE user_sessions (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  token TEXT NOT NULL,
  expires_at DATETIME,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (user_id) REFERENCES users(id)
);
```

**Step 3: Initialize Local Database**
```bash
npx wrangler d1 execute chasemycareer-db --local --file=./schema.sql
```

**Step 4: Initialize Remote Database**
```bash
npx wrangler d1 execute chasemycareer-db --remote --file=./schema.sql
```

### 2.3 Supabase Database Setup

**Step 1: Create Supabase Project**
1. Go to https://supabase.com
2. Click New Project
3. Enter project details:
   - Name: chasemycareer
   - Database Password: (generate strong password)
   - Region: (select closest to your users)
4. Click Create New Project

**Step 2: Create Supabase Tables**

Navigate to SQL Editor in Supabase dashboard and execute:

```sql
-- File Storage for Resumes and Cover Letters
CREATE TABLE resume_files (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id TEXT NOT NULL,
  resume_id TEXT NOT NULL,
  file_name TEXT NOT NULL,
  file_path TEXT NOT NULL,
  file_size INTEGER,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE cover_letter_files (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id TEXT NOT NULL,
  cover_letter_id TEXT NOT NULL,
  file_name TEXT NOT NULL,
  file_path TEXT NOT NULL,
  file_size INTEGER,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Analytics Data
CREATE TABLE user_activity_logs (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id TEXT NOT NULL,
  activity_type TEXT NOT NULL,
  activity_data JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Create indexes
CREATE INDEX idx_resume_files_user_id ON resume_files(user_id);
CREATE INDEX idx_cover_letter_files_user_id ON cover_letter_files(user_id);
CREATE INDEX idx_activity_logs_user_id ON user_activity_logs(user_id);
CREATE INDEX idx_activity_logs_created_at ON user_activity_logs(created_at);
```

**Step 3: Configure Storage Buckets**

1. Navigate to Storage in Supabase dashboard
2. Create new bucket: `resumes`
   - Public: No
   - File size limit: 5MB
   - Allowed MIME types: application/pdf
3. Create new bucket: `cover-letters`
   - Public: No
   - File size limit: 5MB
   - Allowed MIME types: application/pdf

**Step 4: Set Storage Policies**

Execute in SQL Editor:

```sql
-- Resume bucket policies
CREATE POLICY \"Users can upload their own resumes\"
ON storage.objects FOR INSERT
TO authenticated
WITH CHECK (bucket_id = 'resumes' AND auth.uid()::text = (storage.foldername(name))[1]);

CREATE POLICY \"Users can view their own resumes\"
ON storage.objects FOR SELECT
TO authenticated
USING (bucket_id = 'resumes' AND auth.uid()::text = (storage.foldername(name))[1]);

CREATE POLICY \"Users can delete their own resumes\"
ON storage.objects FOR DELETE
TO authenticated
USING (bucket_id = 'resumes' AND auth.uid()::text = (storage.foldername(name))[1]);

-- Cover letter bucket policies
CREATE POLICY \"Users can upload their own cover letters\"
ON storage.objects FOR INSERT
TO authenticated
WITH CHECK (bucket_id = 'cover-letters' AND auth.uid()::text = (storage.foldername(name))[1]);

CREATE POLICY \"Users can view their own cover letters\"
ON storage.objects FOR SELECT
TO authenticated
USING (bucket_id = 'cover-letters' AND auth.uid()::text = (storage.foldername(name))[1]);

CREATE POLICY \"Users can delete their own cover letters\"
ON storage.objects FOR DELETE
TO authenticated
USING (bucket_id = 'cover-letters' AND auth.uid()::text = (storage.foldername(name))[1]);
```

**Step 5: Get Supabase Credentials**

1. Navigate to Project Settings > API
2. Copy the following:
   - Project URL (SUPABASE_URL)
   - anon/public key (SUPABASE_KEY)
   - service_role key (SUPABASE_SERVICE_KEY) - for admin operations

### 2.4 Wrangler Configuration

Update `wrangler.jsonc`:

```json
{
  \"name\": \"chasemycareer-backend\",
  \"main\": \"src/index.ts\",
  \"compatibility_date\": \"2024-01-01\",
  \"d1_databases\": [
    {
      \"binding\": \"DB\",
      \"database_name\": \"chasemycareer-db\",
      \"database_id\": \"<your-database-id>\"
    }
  ],
  \"vars\": {
    \"JWT_SECRET\": \"<your-jwt-secret>\",
    \"GOOGLE_CLIENT_ID\": \"<your-google-client-id>\",
    \"GOOGLE_CLIENT_SECRET\": \"<your-google-client-secret>\",
    \"LINKEDIN_CLIENT_ID\": \"<your-linkedin-client-id>\",
    \"LINKEDIN_CLIENT_SECRET\": \"<your-linkedin-client-secret>\",
    \"SUPABASE_URL\": \"<your-supabase-url>\",
    \"SUPABASE_KEY\": \"<your-supabase-key>\",
    \"SUPABASE_SERVICE_KEY\": \"<your-supabase-service-key>\"
  }
}
```

### 2.5 Frontend Package Configuration

Update `chasemycareer-frontend/package.json`:

```json
{
  \"name\": \"chasemycareer-frontend\",
  \"description\": \"ChaseMyCareer Frontend - React Application\",
  \"version\": \"1.0.0\",
  \"type\": \"module\",
  \"scripts\": {
    \"dev\": \"vite\",
    \"build\": \"tsc && vite build\",
    \"preview\": \"vite preview\",
    \"lint\": \"eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0\"
  },
  \"dependencies\": {
    \"react\": \"^18.2.0\",
    \"react-dom\": \"^18.2.0\",
    \"react-router-dom\": \"^6.20.0\",
    \"@supabase/supabase-js\": \"^2.38.0\"
  },
  \"devDependencies\": {
    \"@types/react\": \"^18.2.43\",
    \"@types/react-dom\": \"^18.2.17\",
    \"@types/react-router-dom\": \"^5.3.3\",
    \"@typescript-eslint/eslint-plugin\": \"^6.14.0\",
    \"@typescript-eslint/parser\": \"^6.14.0\",
    \"@vitejs/plugin-react\": \"^4.2.1\",
    \"eslint\": \"^8.55.0\",
    \"eslint-plugin-react-hooks\": \"^4.6.0\",
    \"eslint-plugin-react-refresh\": \"^0.4.5\",
    \"typescript\": \"^5.2.2\",
    \"vite\": \"^5.0.8\"
  }
}
```

---

## 3. Authentication System

### 3.1 Authentication Methods

**Supported Methods:**
1. Email + Password (native registration)
2. Google OAuth
3. LinkedIn OAuth

### 3.2 Authentication Flow

**Email/Password Registration:**
- User submits email, password, full name
- Backend validates input, hashes password with bcrypt
- Creates user record in D1 database
- Initializes 50 daily tasks with curriculum topics
- Returns JWT token

**OAuth Flow (Google/LinkedIn):**
- User clicks OAuth provider button
- Redirects to provider authorization page
- Provider returns authorization code
- Backend exchanges code for access token
- Fetches user profile from provider
- Creates or updates user record in D1
- Initializes daily tasks if new user
- Returns JWT token

### 3.3 API Endpoints

**POST /api/auth/register**
- Body: `{ email, password, full_name }`
- Response: `{ token, user: { id, email, role } }`

**POST /api/auth/login**
- Body: `{ email, password }`
- Response: `{ token, user: { id, email, role } }`

**GET /api/auth/google**
- Redirects to Google OAuth consent screen

**GET /api/auth/google/callback**
- Query: `?code=<authorization-code>`
- Response: `{ token, user: { id, email, role } }`

**GET /api/auth/linkedin**
- Redirects to LinkedIn OAuth consent screen

**GET /api/auth/linkedin/callback**
- Query: `?code=<authorization-code>`
- Response: `{ token, user: { id, email, role } }`

---

## 4. User Dashboard

### 4.1 Dashboard Components

**Main Navigation:**
- 50-Day Progress
- Applications
- Resume Builder
- Cover Letter Generator
- Profile Settings

**50-Day Progress View:**
- Calendar grid displaying Days 1-50
- Each day shows:
  - Day number
  - Topic title
  - Completion status (checkbox)
  - Brief description
- Visual progress indicator (percentage completed)
- Current day highlight

**Applications Tracker:**
- List view of all job applications
- Columns: Company, Position, Status, Applied Date, Actions
- Filter by status: All, Applied, Interview, Offer, Rejected
- Add new application button
- Edit/Delete application actions

**Resume Builder:**
- Multiple resume templates
- Sections: Personal Info, Work Experience, Education, Skills
- Real-time preview
- Save multiple versions
- Download as PDF

**Cover Letter Generator:**
- Template-based creation
- Fields: Company Name, Position, Custom content
- Save and manage multiple cover letters
- Download as PDF

### 4.2 User Dashboard API Endpoints

**GET /api/user/dashboard**
- Returns: User profile, progress summary, recent applications

**GET /api/tasks**
- Returns: All 50 daily tasks with completion status

**PUT /api/tasks/:taskId**
- Body: `{ completed: true/false }`
- Updates task completion status

**GET /api/applications**
- Query: `?page=1&limit=20&status=all`
- Returns: Paginated job applications

**POST /api/applications**
- Body: `{ company_name, position_title, job_url, status, notes }`
- Creates new application record

**PUT /api/applications/:id**
- Body: `{ status, notes }`
- Updates application

**DELETE /api/applications/:id**
- Deletes application

**GET /api/resumes**
- Returns: All user resumes

**POST /api/resumes**
- Body: `{ title, content }`
- Creates new resume

**GET /api/resumes/:id/pdf**
- Returns: PDF file download

**GET /api/cover-letters**
- Returns: All user cover letters

**POST /api/cover-letters**
- Body: `{ title, content, company_name, position_title }`
- Creates new cover letter

---

## 5. Admin Dashboard

### 5.1 Admin Dashboard Components

**Overview Panel:**
- Total number of registered users
- Active participants (users with >0 completed tasks)
- New registrations (last 7 days)
- Average completion rate

**User Management:**
- Searchable user list
- Columns: Name, Email, Registration Date, Progress, Status, Actions
- View user details (read-only access to user dashboard)
- Send message to individual user
- Suspend/Activate user account

**Messaging System:**
- Compose message form
- Recipients: Individual user or All users
- Subject and message body
- Message history

**Analytics:**
- User engagement charts
- Task completion trends
- Application submission statistics

### 5.2 Admin Dashboard API Endpoints

**GET /api/admin/stats**
- Returns: Total users, active participants, new registrations, completion rates

**GET /api/admin/users**
- Query: `?page=1&limit=50&search=<query>`
- Returns: Paginated user list with progress data

**GET /api/admin/users/:userId**
- Returns: Complete user profile and activity data

**POST /api/admin/messages**
- Body: `{ recipient_id, subject, message }` (recipient_id null for broadcast)
- Sends message to user(s)

**GET /api/admin/messages**
- Returns: Message history

**PUT /api/admin/users/:userId/status**
- Body: `{ status: 'active'/'suspended' }`
- Updates user account status

---

## 6. 50-Day Career Development Curriculum

### 6.1 Complete Day-by-Day Topics

**Week 1: Foundation & Self-Assessment**
- Day 1: Career Goals Definition - Define your short-term and long-term career objectives
- Day 2: Skills Inventory - List your technical and soft skills
- Day 3: Industry Research - Research target industries and companies
- Day 4: Resume Audit - Review and update your current resume
- Day 5: LinkedIn Profile Optimization - Enhance your LinkedIn profile with keywords
- Day 6: Personal Branding - Define your unique value proposition
- Day 7: Week 1 Review - Reflect on progress and adjust goals

**Week 2: Resume & Cover Letter Mastery**
- Day 8: Resume Format Selection - Choose the best resume format for your experience
- Day 9: Achievement Quantification - Add metrics to your accomplishments
- Day 10: Keyword Optimization - Incorporate industry-specific keywords
- Day 11: Cover Letter Template - Create a master cover letter template
- Day 12: Tailoring Techniques - Learn to customize applications
- Day 13: Portfolio Development - Start building your work portfolio
- Day 14: Week 2 Review - Finalize resume and cover letter versions

**Week 3: Job Search Strategy**
- Day 15: Job Board Setup - Create accounts on major job platforms
- Day 16: Company Target List - Identify 20 dream companies
- Day 17: Application Tracking System - Set up your application tracker
- Day 18: Daily Application Goal - Commit to applying to 2-3 jobs daily
- Day 19: Networking Strategy - Plan your networking approach
- Day 20: Informational Interviews - Reach out for informational interviews
- Day 21: Week 3 Review - Assess application progress

**Week 4: Networking & Online Presence**
- Day 22: LinkedIn Connections - Connect with 10 industry professionals
- Day 23: LinkedIn Engagement - Comment on 5 industry posts daily
- Day 24: Alumni Network - Reach out to alumni in target companies
- Day 25: Professional Associations - Join relevant industry groups
- Day 26: Twitter/X Professional Profile - Create or optimize professional social media
- Day 27: Personal Website - Start building a personal website or portfolio
- Day 28: Week 4 Review - Evaluate networking effectiveness

**Week 5: Interview Preparation**
- Day 29: Common Questions - Practice answers to 10 common interview questions
- Day 30: STAR Method - Master the STAR response technique
- Day 31: Behavioral Questions - Prepare stories for behavioral interviews
- Day 32: Technical Prep - Review technical skills and concepts
- Day 33: Mock Interview - Conduct a mock interview with a friend
- Day 34: Company Research - Deep dive into target company cultures
- Day 35: Week 5 Review - Refine interview responses

**Week 6: Advanced Interview Skills**
- Day 36: Salary Negotiation - Research salary ranges and practice negotiation
- Day 37: Questions to Ask - Prepare thoughtful questions for interviewers
- Day 38: Virtual Interview Setup - Test your video interview setup
- Day 39: Body Language - Practice confident body language
- Day 40: Follow-up Strategy - Learn effective post-interview follow-up
- Day 41: Rejection Handling - Develop resilience strategies
- Day 42: Week 6 Review - Consolidate interview skills

**Week 7: Momentum & Persistence**
- Day 43: Application Surge - Apply to 5 jobs today
- Day 44: Referral Requests - Ask for referrals from connections
- Day 45: Skills Gap Analysis - Identify and address skill gaps
- Day 46: Online Course Enrollment - Start a relevant online course
- Day 47: Volunteer/Freelance - Explore short-term projects
- Day 48: Recruiter Outreach - Connect with 3 recruiters
- Day 49: Week 7 Review - Analyze response rates

**Week 8: Final Push & Offer Management**
- Day 50: Offer Evaluation - Learn to evaluate job offers comprehensively

### 6.2 Task Initialization Logic

When a new user registers, the system automatically creates 50 daily_tasks records with:
- Sequential day_number (1-50)
- Corresponding topic from the curriculum above
- Brief description for each topic
- completed = 0 (uncompleted)
- user_id linked to the new user

---

## 7. Database Schema Details

### 7.1 Cloudflare D1 Tables

**users**
- Primary storage for user authentication
- Fields: id, email, password_hash, full_name, auth_provider, google_id, linkedin_id, role, created_at, updated_at

**user_profiles**
- Extended user information
- Fields: user_id, phone, location, target_role, experience_level, preferred_industries

**daily_tasks**
- 50-day curriculum tracking
- Fields: id, user_id, day_number, topic, description, completed, completed_at

**job_applications**
- Application tracking
- Fields: id, user_id, company_name, position_title, job_url, status, applied_date, notes, created_at

**resumes**
- Resume storage
- Fields: id, user_id, title, content, created_at, updated_at

**cover_letters**
- Cover letter storage
- Fields: id, user_id, title, content, company_name, position_title, created_at

**admin_messages**
- Admin-to-user messaging
- Fields: id, admin_id, recipient_id, subject, message, sent_at

**user_sessions**
- Session management
- Fields: id, user_id, token, expires_at, created_at

### 7.2 Supabase Tables (Supplementary)

Supabase is used for:
- File storage (resume PDFs, cover letter PDFs)
- Real-time messaging features
- Complex analytics queries

**resume_files**
- PDF file metadata
- Fields: id, user_id, resume_id, file_name, file_path, file_size, created_at

**cover_letter_files**
- PDF file metadata
- Fields: id, user_id, cover_letter_id, file_name, file_path, file_size, created_at

**user_activity_logs**
- Analytics and activity tracking
- Fields: id, user_id, activity_type, activity_data, created_at

---

## 8. Testing Implementation

### 8.1 Unit Testing

**Testing Framework: Vitest**

Create `vitest.config.ts`:

```typescript
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'dist/',
        '**/*.config.ts',
        '**/*.test.ts'
      ]
    }
  }
});
```

**Unit Test Structure:**

Create `tests/unit/` directory with the following test files:

**tests/unit/auth.test.ts**
```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import { hashPassword, verifyPassword, generateJWT, verifyJWT } from '../../src/utils/auth';

describe('Authentication Utils', () => {
  describe('Password Hashing', () => {
    it('should hash password correctly', async () => {
      const password = 'testPassword123';
      const hash = await hashPassword(password);
      expect(hash).toBeDefined();
      expect(hash).not.toBe(password);
    });

    it('should verify correct password', async () => {
      const password = 'testPassword123';
      const hash = await hashPassword(password);
      const isValid = await verifyPassword(password, hash);
      expect(isValid).toBe(true);
    });

    it('should reject incorrect password', async () => {
      const password = 'testPassword123';
      const hash = await hashPassword(password);
      const isValid = await verifyPassword('wrongPassword', hash);
      expect(isValid).toBe(false);
    });
  });

  describe('JWT Token', () => {
    it('should generate valid JWT token', () => {
      const payload = { userId: 'test-123', role: 'user' };
      const token = generateJWT(payload, 'test-secret');
      expect(token).toBeDefined();
      expect(typeof token).toBe('string');
    });

    it('should verify valid JWT token', () => {
      const payload = { userId: 'test-123', role: 'user' };
      const token = generateJWT(payload, 'test-secret');
      const decoded = verifyJWT(token, 'test-secret');
      expect(decoded.userId).toBe('test-123');
      expect(decoded.role).toBe('user');
    });

    it('should reject invalid JWT token', () => {
      expect(() => verifyJWT('invalid-token', 'test-secret')).toThrow();
    });
  });
});
```

**tests/unit/tasks.test.ts**
```typescript
import { describe, it, expect } from 'vitest';
import { generateDailyTasks, calculateProgress } from '../../src/utils/tasks';

describe('Task Management', () => {
  describe('Daily Tasks Generation', () => {
    it('should generate 50 daily tasks', () => {
      const userId = 'test-user-123';
      const tasks = generateDailyTasks(userId);
      expect(tasks).toHaveLength(50);
    });

    it('should have sequential day numbers', () => {
      const userId = 'test-user-123';
      const tasks = generateDailyTasks(userId);
      tasks.forEach((task, index) => {
        expect(task.day_number).toBe(index + 1);
      });
    });

    it('should have valid topics for all days', () => {
      const userId = 'test-user-123';
      const tasks = generateDailyTasks(userId);
      tasks.forEach(task => {
        expect(task.topic).toBeDefined();
        expect(task.topic.length).toBeGreaterThan(0);
      });
    });
  });

  describe('Progress Calculation', () => {
    it('should calculate 0% for no completed tasks', () => {
      const tasks = Array(50).fill({ completed: 0 });
      const progress = calculateProgress(tasks);
      expect(progress).toBe(0);
    });

    it('should calculate 100% for all completed tasks', () => {
      const tasks = Array(50).fill({ completed: 1 });
      const progress = calculateProgress(tasks);
      expect(progress).toBe(100);
    });

    it('should calculate 50% for half completed tasks', () => {
      const tasks = [
        ...Array(25).fill({ completed: 1 }),
        ...Array(25).fill({ completed: 0 })
      ];
      const progress = calculateProgress(tasks);
      expect(progress).toBe(50);
    });
  });
});
```

**tests/unit/validation.test.ts**
```typescript
import { describe, it, expect } from 'vitest';
import { validateEmail, validatePassword, validateApplicationData } from '../../src/utils/validation';

describe('Input Validation', () => {
  describe('Email Validation', () => {
    it('should accept valid email', () => {
      expect(validateEmail('test@example.com')).toBe(true);
      expect(validateEmail('user.name@domain.co.uk')).toBe(true);
    });

    it('should reject invalid email', () => {
      expect(validateEmail('invalid-email')).toBe(false);
      expect(validateEmail('@example.com')).toBe(false);
      expect(validateEmail('test@')).toBe(false);
    });
  });

  describe('Password Validation', () => {
    it('should accept strong password', () => {
      expect(validatePassword('StrongPass123!')).toBe(true);
    });

    it('should reject weak password', () => {
      expect(validatePassword('weak')).toBe(false);
      expect(validatePassword('12345678')).toBe(false);
    });
  });

  describe('Application Data Validation', () => {
    it('should accept valid application data', () => {
      const data = {
        company_name: 'Tech Corp',
        position_title: 'Software Engineer',
        status: 'applied'
      };
      expect(validateApplicationData(data)).toBe(true);
    });

    it('should reject incomplete application data', () => {
      const data = {
        company_name: 'Tech Corp'
      };
      expect(validateApplicationData(data)).toBe(false);
    });
  });
});
```

**Run Unit Tests:**
```bash
npm run test:unit
```

Add to `package.json`:
```json
{
  \"scripts\": {
    \"test:unit\": \"vitest run tests/unit\",
    \"test:unit:watch\": \"vitest watch tests/unit\",
    \"test:unit:coverage\": \"vitest run tests/unit --coverage\"
  }
}
```

### 8.2 Integration Testing

**Testing Framework: Vitest + Supertest**

Create `tests/integration/` directory:

**tests/integration/auth.integration.test.ts**
```typescript
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import request from 'supertest';

const API_URL = 'http://localhost:8787';

describe('Authentication Integration Tests', () => {
  let testUserId: string;
  let authToken: string;

  describe('POST /api/auth/register', () => {
    it('should register new user successfully', async () => {
      const response = await request(API_URL)
        .post('/api/auth/register')
        .send({
          email: 'test@example.com',
          password: 'TestPass123!',
          full_name: 'Test User'
        });

      expect(response.status).toBe(201);
      expect(response.body).toHaveProperty('token');
      expect(response.body.user).toHaveProperty('id');
      expect(response.body.user.email).toBe('test@example.com');
      
      testUserId = response.body.user.id;
      authToken = response.body.token;
    });

    it('should reject duplicate email', async () => {
      const response = await request(API_URL)
        .post('/api/auth/register')
        .send({
          email: 'test@example.com',
          password: 'TestPass123!',
          full_name: 'Test User 2'
        });

      expect(response.status).toBe(409);
      expect(response.body).toHaveProperty('error');
    });

    it('should reject invalid email format', async () => {
      const response = await request(API_URL)
        .post('/api/auth/register')
        .send({
          email: 'invalid-email',
          password: 'TestPass123!',
          full_name: 'Test User'
        });

      expect(response.status).toBe(400);
    });
  });

  describe('POST /api/auth/login', () => {
    it('should login with correct credentials', async () => {
      const response = await request(API_URL)
        .post('/api/auth/login')
        .send({
          email: 'test@example.com',
          password: 'TestPass123!'
        });

      expect(response.status).toBe(200);
      expect(response.body).toHaveProperty('token');
      expect(response.body.user.email).toBe('test@example.com');
    });

    it('should reject incorrect password', async () => {
      const response = await request(API_URL)
        .post('/api/auth/login')
        .send({
          email: 'test@example.com',
          password: 'WrongPassword'
        });

      expect(response.status).toBe(401);
    });

    it('should reject non-existent user', async () => {
      const response = await request(API_URL)
        .post('/api/auth/login')
        .send({
          email: 'nonexistent@example.com',
          password: 'TestPass123!'
        });

      expect(response.status).toBe(404);
    });
  });
});
```

**tests/integration/tasks.integration.test.ts**
```typescript
import { describe, it, expect, beforeAll } from 'vitest';
import request from 'supertest';

const API_URL = 'http://localhost:8787';

describe('Tasks Integration Tests', () => {
  let authToken: string;
  let taskId: string;

  beforeAll(async () => {
    const response = await request(API_URL)
      .post('/api/auth/login')
      .send({
        email: 'test@example.com',
        password: 'TestPass123!'
      });
    authToken = response.body.token;
  });

  describe('GET /api/tasks', () => {
    it('should return all 50 tasks for authenticated user', async () => {
      const response = await request(API_URL)
        .get('/api/tasks')
        .set('Authorization', `Bearer ${authToken}`);

      expect(response.status).toBe(200);
      expect(response.body).toHaveLength(50);
      expect(response.body[0]).toHaveProperty('day_number');
      expect(response.body[0]).toHaveProperty('topic');
      expect(response.body[0]).toHaveProperty('completed');
      
      taskId = response.body[0].id;
    });

    it('should reject unauthenticated request', async () => {
      const response = await request(API_URL)
        .get('/api/tasks');

      expect(response.status).toBe(401);
    });
  });

  describe('PUT /api/tasks/:taskId', () => {
    it('should mark task as completed', async () => {
      const response = await request(API_URL)
        .put(`/api/tasks/${taskId}`)
        .set('Authorization', `Bearer ${authToken}`)
        .send({ completed: true });

      expect(response.status).toBe(200);
      expect(response.body.completed).toBe(1);
      expect(response.body).toHaveProperty('completed_at');
    });

    it('should mark task as incomplete', async () => {
      const response = await request(API_URL)
        .put(`/api/tasks/${taskId}`)
        .set('Authorization', `Bearer ${authToken}`)
        .send({ completed: false });

      expect(response.status).toBe(200);
      expect(response.body.completed).toBe(0);
    });
  });
});
```

**tests/integration/applications.integration.test.ts**
```typescript
import { describe, it, expect, beforeAll } from 'vitest';
import request from 'supertest';

const API_URL = 'http://localhost:8787';

describe('Applications Integration Tests', () => {
  let authToken: string;
  let applicationId: string;

  beforeAll(async () => {
    const response = await request(API_URL)
      .post('/api/auth/login')
      .send({
        email: 'test@example.com',
        password: 'TestPass123!'
      });
    authToken = response.body.token;
  });

  describe('POST /api/applications', () => {
    it('should create new application', async () => {
      const response = await request(API_URL)
        .post('/api/applications')
        .set('Authorization', `Bearer ${authToken}`)
        .send({
          company_name: 'Tech Corp',
          position_title: 'Software Engineer',
          job_url: 'https://example.com/job',
          status: 'applied',
          notes: 'Applied via LinkedIn'
        });

      expect(response.status).toBe(201);
      expect(response.body).toHaveProperty('id');
      expect(response.body.company_name).toBe('Tech Corp');
      
      applicationId = response.body.id;
    });

    it('should reject incomplete application data', async () => {
      const response = await request(API_URL)
        .post('/api/applications')
        .set('Authorization', `Bearer ${authToken}`)
        .send({
          company_name: 'Tech Corp'
        });

      expect(response.status).toBe(400);
    });
  });

  describe('GET /api/applications', () => {
    it('should return all applications', async () => {
      const response = await request(API_URL)
        .get('/api/applications')
        .set('Authorization', `Bearer ${authToken}`);

      expect(response.status).toBe(200);
      expect(Array.isArray(response.body)).toBe(true);
      expect(response.body.length).toBeGreaterThan(0);
    });

    it('should filter by status', async () => {
      const response = await request(API_URL)
        .get('/api/applications?status=applied')
        .set('Authorization', `Bearer ${authToken}`);

      expect(response.status).toBe(200);
      response.body.forEach(app => {
        expect(app.status).toBe('applied');
      });
    });
  });

  describe('PUT /api/applications/:id', () => {
    it('should update application status', async () => {
      const response = await request(API_URL)
        .put(`/api/applications/${applicationId}`)
        .set('Authorization', `Bearer ${authToken}`)
        .send({
          status: 'interview',
          notes: 'Phone interview scheduled'
        });

      expect(response.status).toBe(200);
      expect(response.body.status).toBe('interview');
    });
  });

  describe('DELETE /api/applications/:id', () => {
    it('should delete application', async () => {
      const response = await request(API_URL)
        .delete(`/api/applications/${applicationId}`)
        .set('Authorization', `Bearer ${authToken}`);

      expect(response.status).toBe(204);
    });
  });
});
```

**Run Integration Tests:**
```bash
npm run test:integration
```

Add to `package.json`:
```json
{
  \"scripts\": {
    \"test:integration\": \"vitest run tests/integration\",
    \"test:integration:watch\": \"vitest watch tests/integration\"
  }
}
```

### 8.3 Manual Testing Procedures

Create `MANUAL_TESTING.md` file:

```markdown
# Manual Testing Procedures

## Pre-Testing Setup

1. Start local development server:
   ```bash
   npx wrangler dev
   ```

2. Ensure local D1 database is initialized
3. Have test credentials ready:
   - Email: manual-test@example.com
   - Password: ManualTest123!

## Test Suite 1: User Registration & Authentication

### Test Case 1.1: Email Registration
**Steps:**
1. Navigate to `/signup`
2. Enter email: manual-test@example.com
3. Enter password: ManualTest123!
4. Enter full name: Manual Test User
5. Click Register button

**Expected Results:**
- Registration successful
- Redirected to dashboard
- 50 daily tasks created
- User profile visible

**Pass/Fail:** ___________

### Test Case 1.2: Email Login
**Steps:**
1. Navigate to `/login`
2. Enter email: manual-test@example.com
3. Enter password: ManualTest123!
4. Click Login button

**Expected Results:**
- Login successful
- Redirected to dashboard
- User data loaded correctly

**Pass/Fail:** ___________

### Test Case 1.3: Google OAuth
**Steps:**
1. Navigate to `/login`
2. Click Sign in with Google button
3. Complete Google authentication

**Expected Results:**
- OAuth flow completes
- User created/logged in
- Redirected to dashboard

**Pass/Fail:** ___________

### Test Case 1.4: LinkedIn OAuth
**Steps:**
1. Navigate to `/login`
2. Click Sign in with LinkedIn button
3. Complete LinkedIn authentication

**Expected Results:**
- OAuth flow completes
- User created/logged in
- Redirected to dashboard

**Pass/Fail:** ___________

## Test Suite 2: 50-Day Progress Tracking

### Test Case 2.1: View All Tasks
**Steps:**
1. Login to dashboard
2. Navigate to 50-Day Progress section

**Expected Results:**
- All 50 days displayed in calendar grid
- Each day shows day number, topic, description
- Completion checkboxes visible
- Progress percentage displayed (0% initially)

**Pass/Fail:** ___________

### Test Case 2.2: Mark Task Complete
**Steps:**
1. Navigate to 50-Day Progress
2. Click checkbox for Day 1
3. Verify completion status

**Expected Results:**
- Checkbox marked as checked
- completed_at timestamp recorded
- Progress percentage updates (2%)
- Visual indicator shows completion

**Pass/Fail:** ___________

### Test Case 2.3: Mark Task Incomplete
**Steps:**
1. Navigate to 50-Day Progress
2. Click checkbox for previously completed Day 1
3. Verify completion status

**Expected Results:**
- Checkbox unmarked
- completed_at cleared
- Progress percentage updates (0%)

**Pass/Fail:** ___________

### Test Case 2.4: Progress Calculation
**Steps:**
1. Mark 25 tasks as complete
2. Check progress indicator

**Expected Results:**
- Progress shows 50%
- Visual progress bar reflects percentage

**Pass/Fail:** ___________

## Test Suite 3: Job Applications Management

### Test Case 3.1: Create Application
**Steps:**
1. Navigate to Applications section
2. Click Add New Application
3. Fill form:
   - Company: Tech Corp
   - Position: Software Engineer
   - URL: https://example.com/job
   - Status: Applied
   - Notes: Applied via LinkedIn
4. Click Save

**Expected Results:**
- Application created successfully
- Appears in applications list
- All fields saved correctly

**Pass/Fail:** ___________

### Test Case 3.2: View Applications List
**Steps:**
1. Navigate to Applications section
2. View list of all applications

**Expected Results:**
- All applications displayed
- Columns show: Company, Position, Status, Applied Date, Actions
- Pagination works (if >20 applications)

**Pass/Fail:** ___________

### Test Case 3.3: Filter by Status
**Steps:**
1. Navigate to Applications section
2. Select status filter: Interview
3. View filtered results

**Expected Results:**
- Only applications with Interview status shown
- Filter updates list correctly

**Pass/Fail:** ___________

### Test Case 3.4: Update Application
**Steps:**
1. Navigate to Applications section
2. Click Edit on an application
3. Change status to Interview
4. Add note: Phone interview scheduled
5. Click Save

**Expected Results:**
- Application updated successfully
- New status and notes saved
- Changes reflected in list

**Pass/Fail:** ___________

### Test Case 3.5: Delete Application
**Steps:**
1. Navigate to Applications section
2. Click Delete on an application
3. Confirm deletion

**Expected Results:**
- Application deleted successfully
- Removed from list
- Database record deleted

**Pass/Fail:** ___________

## Test Suite 4: Resume Builder

### Test Case 4.1: Create Resume
**Steps:**
1. Navigate to Resume Builder
2. Enter title: Software Engineer Resume
3. Fill sections: Personal Info, Work Experience, Education, Skills
4. Click Save

**Expected Results:**
- Resume created successfully
- Preview displays correctly
- Saved to database

**Pass/Fail:** ___________

### Test Case 4.2: Download Resume as PDF
**Steps:**
1. Navigate to Resume Builder
2. Select saved resume
3. Click Download PDF

**Expected Results:**
- PDF generated successfully
- File downloads to local machine
- PDF content matches resume data

**Pass/Fail:** ___________

### Test Case 4.3: Edit Resume
**Steps:**
1. Navigate to Resume Builder
2. Select existing resume
3. Modify content
4. Click Save

**Expected Results:**
- Resume updated successfully
- Changes saved to database
- updated_at timestamp updated

**Pass/Fail:** ___________

## Test Suite 5: Cover Letter Generator

### Test Case 5.1: Create Cover Letter
**Steps:**
1. Navigate to Cover Letter Generator
2. Enter:
   - Title: Tech Corp Application
   - Company: Tech Corp
   - Position: Software Engineer
   - Content: (custom letter content)
3. Click Save

**Expected Results:**
- Cover letter created successfully
- Saved to database
- Appears in cover letters list

**Pass/Fail:** ___________

### Test Case 5.2: Download Cover Letter as PDF
**Steps:**
1. Navigate to Cover Letter Generator
2. Select saved cover letter
3. Click Download PDF

**Expected Results:**
- PDF generated successfully
- File downloads to local machine
- PDF content matches cover letter data

**Pass/Fail:** ___________

## Test Suite 6: Admin Dashboard

### Test Case 6.1: Admin Login
**Steps:**
1. Login with admin credentials
2. Navigate to `/admin/dashboard`

**Expected Results:**
- Admin dashboard accessible
- Overview panel displays statistics
- User management section visible

**Pass/Fail:** ___________

### Test Case 6.2: View User Statistics
**Steps:**
1. Login as admin
2. View overview panel

**Expected Results:**
- Total users count displayed
- Active participants count displayed
- New registrations (last 7 days) displayed
- Average completion rate displayed

**Pass/Fail:** ___________

### Test Case 6.3: Search Users
**Steps:**
1. Navigate to Admin > User Management
2. Enter search query: manual-test
3. View results

**Expected Results:**
- Search results filtered correctly
- Matching users displayed
- User details visible

**Pass/Fail:** ___________

### Test Case 6.4: View User Details
**Steps:**
1. Navigate to Admin > User Management
2. Click View Details on a user

**Expected Results:**
- User profile displayed
- Task completion status visible
- Application history visible
- Read-only access to user dashboard

**Pass/Fail:** ___________

### Test Case 6.5: Send Message to User
**Steps:**
1. Navigate to Admin > Messaging
2. Select recipient user
3. Enter subject: Test Message
4. Enter message content
5. Click Send

**Expected Results:**
- Message sent successfully
- Saved to admin_messages table
- Appears in message history

**Pass/Fail:** ___________

### Test Case 6.6: Broadcast Message
**Steps:**
1. Navigate to Admin > Messaging
2. Select All Users as recipient
3. Enter subject and message
4. Click Send

**Expected Results:**
- Message sent to all users
- Multiple records created in admin_messages
- Confirmation displayed

**Pass/Fail:** ___________

### Test Case 6.7: Suspend User Account
**Steps:**
1. Navigate to Admin > User Management
2. Select a user
3. Click Suspend Account
4. Confirm action

**Expected Results:**
- User account suspended
- User cannot login
- Status updated in database

**Pass/Fail:** ___________

### Test Case 6.8: Activate User Account
**Steps:**
1. Navigate to Admin > User Management
2. Select suspended user
3. Click Activate Account
4. Confirm action

**Expected Results:**
- User account activated
- User can login again
- Status updated in database

**Pass/Fail:** ___________

## Test Suite 7: Security & Authorization

### Test Case 7.1: Protected Routes
**Steps:**
1. Logout from application
2. Attempt to access `/dashboard` directly

**Expected Results:**
- Redirected to login page
- Access denied without authentication

**Pass/Fail:** ___________

### Test Case 7.2: Admin-Only Routes
**Steps:**
1. Login as regular user
2. Attempt to access `/admin/dashboard`

**Expected Results:**
- Access denied
- Error message displayed
- Redirected to user dashboard

**Pass/Fail:** ___________

### Test Case 7.3: Data Isolation
**Steps:**
1. Login as User A
2. Note User A's applications
3. Logout and login as User B
4. View User B's applications

**Expected Results:**
- User B cannot see User A's data
- Each user sees only their own data
- Data properly isolated by user_id

**Pass/Fail:** ___________

## Test Suite 8: Error Handling

### Test Case 8.1: Invalid Login Credentials
**Steps:**
1. Navigate to `/login`
2. Enter incorrect email/password
3. Click Login

**Expected Results:**
- Error message displayed
- User not logged in
- Appropriate error status returned

**Pass/Fail:** ___________

### Test Case 8.2: Network Error Handling
**Steps:**
1. Disconnect internet
2. Attempt to perform any action

**Expected Results:**
- Error message displayed
- User notified of connection issue
- No data corruption

**Pass/Fail:** ___________

### Test Case 8.3: Invalid Form Submission
**Steps:**
1. Navigate to application form
2. Submit with missing required fields

**Expected Results:**
- Validation errors displayed
- Form not submitted
- User prompted to correct errors

**Pass/Fail:** ___________

## Test Suite 9: Performance

### Test Case 9.1: Page Load Time
**Steps:**
1. Clear browser cache
2. Navigate to dashboard
3. Measure load time

**Expected Results:**
- Dashboard loads in <3 seconds
- All data fetched successfully

**Pass/Fail:** ___________

### Test Case 9.2: Large Dataset Handling
**Steps:**
1. Create 100+ job applications
2. Navigate to applications list
3. Test pagination and filtering

**Expected Results:**
- Pagination works smoothly
- No performance degradation
- Filters apply quickly

**Pass/Fail:** ___________

## Test Suite 10: Cross-Browser Compatibility

### Test Case 10.1: Chrome
**Steps:**
1. Open application in Chrome
2. Test all major features

**Expected Results:**
- All features work correctly
- UI renders properly

**Pass/Fail:** ___________

### Test Case 10.2: Firefox
**Steps:**
1. Open application in Firefox
2. Test all major features

**Expected Results:**
- All features work correctly
- UI renders properly

**Pass/Fail:** ___________

### Test Case 10.3: Safari
**Steps:**
1. Open application in Safari
2. Test all major features

**Expected Results:**
- All features work correctly
- UI renders properly

**Pass/Fail:** ___________

### Test Case 10.4: Edge
**Steps:**
1. Open application in Edge
2. Test all major features

**Expected Results:**
- All features work correctly
- UI renders properly

**Pass/Fail:** ___________

## Test Summary

**Total Test Cases:** 40
**Passed:** ___________
**Failed:** ___________
**Pass Rate:** ___________%

**Critical Issues Found:**
1. 
2. 
3. 

**Minor Issues Found:**
1. 
2. 
3. 

**Tester Name:** ___________
**Test Date:** ___________
**Environment:** ___________
```

---

## 9. CI/CD Pipeline with GitHub Actions

### 9.1 GitHub Actions Workflow

Create `.github/workflows/ci-cd.yml`:

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run unit tests
      run: npm run test:unit
    
    - name: Run integration tests
      run: npm run test:integration
      env:
        JWT_SECRET: ${{ secrets.JWT_SECRET }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
    
    - name: Generate coverage report
      run: npm run test:unit:coverage
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage/coverage-final.json
        flags: unittests
        name: codecov-umbrella

  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run ESLint
      run: npm run lint
    
    - name: Run TypeScript check
      run: npm run type-check

  build:
    name: Build Application
    runs-on: ubuntu-latest
    needs: [test, lint]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build project
      run: npm run build
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: build-artifacts
        path: dist/

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: https://staging.chasemycareer.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Deploy to Cloudflare Workers (Staging)
      run: npx wrangler deploy --env staging
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://www.chasemycareer.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Deploy to Cloudflare Workers (Production)
      run: npx wrangler deploy --env production
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
    
    - name: Create deployment tag
      run: |
        git config user.name github-actions
        git config user.email github-actions@github.com
        git tag -a v${{ github.run_number }} -m \"Production deployment ${{ github.run_number }}\"
        git push origin v${{ github.run_number }}

  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Send Slack notification
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        text: 'Deployment completed'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      if: always()
```

### 9.2 GitHub Secrets Configuration

Add the following secrets in GitHub repository settings (Settings > Secrets and variables > Actions):

1. `CLOUDFLARE_API_TOKEN`: Cloudflare API token with Workers deployment permissions
2. `CLOUDFLARE_ACCOUNT_ID`: Cloudflare account ID
3. `JWT_SECRET`: Secret key for JWT token generation
4. `SUPABASE_URL`: Supabase project URL
5. `SUPABASE_KEY`: Supabase anon/public key
6. `SUPABASE_SERVICE_KEY`: Supabase service role key
7. `SLACK_WEBHOOK`: (Optional) Slack webhook URL for notifications

### 9.3 Environment Configuration

Update `wrangler.jsonc` to support multiple environments:

```json
{
  \"name\": \"chasemycareer-backend\",
  \"main\": \"src/index.ts\",
  \"compatibility_date\": \"2024-01-01\",
  \"env\": {
    \"staging\": {
      \"name\": \"chasemycareer-backend-staging\",
      \"d1_databases\": [
        {
          \"binding\": \"DB\",
          \"database_name\": \"chasemycareer-db-staging\",
          \"database_id\": \"<staging-database-id>\"
        }
      ],
      \"vars\": {
        \"ENVIRONMENT\": \"staging\"
      }
    },
    \"production\": {
      \"name\": \"chasemycareer-backend-production\",
      \"d1_databases\": [
        {
          \"binding\": \"DB\",
          \"database_name\": \"chasemycareer-db-production\",
          \"database_id\": \"<production-database-id>\"
        }
      ],
      \"vars\": {
        \"ENVIRONMENT\": \"production\"
      }
    }
  }
}
```

---

## 10. Deployment Instructions

### 10.1 Vercel Hosting Deployment

**Note:** Vercel is primarily for frontend hosting. For this project, Cloudflare Workers handles the backend.

**Step 1: Install Vercel CLI**
```bash
npm install -g vercel
```

**Step 2: Login to Vercel**
```bash
vercel login
```

**Step 3: Create `vercel.json` Configuration**
```json
{
  \"version\": 2,
  \"builds\": [
    {
      \"src\": \"package.json\",
      \"use\": \"@vercel/static-build\",
      \"config\": {
        \"distDir\": \"dist\"
      }
    }
  ],
  \"routes\": [
    {
      \"src\": \"/api/(.*)\",
      \"dest\": \"https://chasemycareer-backend.workers.dev/api/$1\"
    },
    {
      \"src\": \"/(.*)\",
      \"dest\": \"/index.html\"
    }
  ],
  \"env\": {
    \"VITE_API_URL\": \"https://chasemycareer-backend.workers.dev\"
  }
}
```

**Step 4: Deploy to Vercel**
```bash
vercel --prod
```

**Step 5: Configure Custom Domain**
1. Go to Vercel dashboard
2. Select your project
3. Navigate to Settings > Domains
4. Add custom domain: www.chasemycareer.com
5. Follow DNS configuration instructions

**Step 6: Set Environment Variables**
1. Navigate to Settings > Environment Variables
2. Add:
   - `VITE_API_URL`: https://chasemycareer-backend.workers.dev
   - `VITE_SUPABASE_URL`: Your Supabase URL
   - `VITE_SUPABASE_KEY`: Your Supabase anon key

### 10.2 Cloudflare Workers Deployment

**Step 1: Install Wrangler CLI**
```bash
npm install -g wrangler
```

**Step 2: Login to Cloudflare**
```bash
wrangler login
```

**Step 3: Create Production Database**
```bash
npx wrangler d1 create chasemycareer-db-production
```

**Step 4: Initialize Production Database**
```bash
npx wrangler d1 execute chasemycareer-db-production --remote --file=./schema.sql
```

**Step 5: Update `wrangler.jsonc` with Production Database ID**
```json
{
  \"env\": {
    \"production\": {
      \"d1_databases\": [
        {
          \"binding\": \"DB\",
          \"database_name\": \"chasemycareer-db-production\",
          \"database_id\": \"<your-production-database-id>\"
        }
      ]
    }
  }
}
```

**Step 6: Set Production Environment Variables**
```bash
wrangler secret put JWT_SECRET --env production
wrangler secret put GOOGLE_CLIENT_ID --env production
wrangler secret put GOOGLE_CLIENT_SECRET --env production
wrangler secret put LINKEDIN_CLIENT_ID --env production
wrangler secret put LINKEDIN_CLIENT_SECRET --env production
wrangler secret put SUPABASE_URL --env production
wrangler secret put SUPABASE_KEY --env production
wrangler secret put SUPABASE_SERVICE_KEY --env production
```

**Step 7: Deploy to Production**
```bash
npx wrangler deploy --env production
```

**Step 8: Verify Deployment**
```bash
curl https://chasemycareer-backend.workers.dev/api/health
```

### 10.3 Cloudflare Pages Deployment (Alternative Frontend Hosting)

**Step 1: Build Frontend**
```bash
cd chasemycareer-frontend
npm run build
```

**Step 2: Deploy to Cloudflare Pages**
```bash
npx wrangler pages deploy dist --project-name=chasemycareer-frontend
```

**Step 3: Configure Custom Domain**
1. Go to Cloudflare dashboard
2. Navigate to Pages > chasemycareer-frontend
3. Go to Custom domains
4. Add domain: www.chasemycareer.com
5. Cloudflare automatically configures DNS

**Step 4: Set Environment Variables**
1. Navigate to Settings > Environment variables
2. Add production variables:
   - `VITE_API_URL`
   - `VITE_SUPABASE_URL`
   - `VITE_SUPABASE_KEY`

### 10.4 Domain Configuration for www.chasemycareer.com

**Step 1: Purchase Domain**
- Purchase chasemycareer.com from domain registrar (Namecheap, GoDaddy, Cloudflare Registrar, etc.)

**Step 2: Add Domain to Cloudflare**
1. Login to Cloudflare dashboard
2. Click Add Site
3. Enter chasemycareer.com
4. Select Free plan
5. Cloudflare scans existing DNS records
6. Click Continue

**Step 3: Update Nameservers**
1. Cloudflare provides nameservers (e.g., ns1.cloudflare.com, ns2.cloudflare.com)
2. Go to your domain registrar
3. Update nameservers to Cloudflare's nameservers
4. Wait for DNS propagation (up to 24 hours)

**Step 4: Configure DNS Records**

In Cloudflare DNS settings, add:

**For Cloudflare Workers:**
```
Type: CNAME
Name: www
Target: chasemycareer-backend.workers.dev
Proxy status: Proxied (orange cloud)
```

**For Root Domain:**
```
Type: CNAME
Name: @
Target: www.chasemycareer.com
Proxy status: Proxied (orange cloud)
```

**For Cloudflare Pages (if using):**
```
Type: CNAME
Name: www
Target: chasemycareer-frontend.pages.dev
Proxy status: Proxied (orange cloud)
```

**Step 5: Configure SSL/TLS**
1. Navigate to SSL/TLS in Cloudflare dashboard
2. Set SSL/TLS encryption mode to Full (strict)
3. Enable Always Use HTTPS
4. Enable Automatic HTTPS Rewrites

**Step 6: Configure Page Rules (Optional)**
1. Navigate to Rules > Page Rules
2. Create rule for http://chasemycareer.com/*
   - Setting: Forwarding URL (301 Permanent Redirect)
   - Destination: https://www.chasemycareer.com/$1

**Step 7: Verify Domain Configuration**
```bash
dig www.chasemycareer.com
nslookup www.chasemycareer.com
curl -I https://www.chasemycareer.com
```

### 10.5 Complete Deployment Checklist

**Pre-Deployment:**
- [ ] All tests passing (unit + integration)
- [ ] Code linted and formatted
- [ ] Environment variables configured
- [ ] Database schemas created
- [ ] Supabase storage buckets configured
- [ ] OAuth credentials obtained (Google, LinkedIn)

**Cloudflare Workers:**
- [ ] Production database created and initialized
- [ ] Secrets configured
- [ ] Workers deployed successfully
- [ ] API endpoints responding correctly

**Frontend Hosting:**
- [ ] Build completed successfully
- [ ] Deployed to Vercel/Cloudflare Pages
- [ ] Environment variables set
- [ ] API connection verified

**Domain Configuration:**
- [ ] Domain purchased
- [ ] Nameservers updated
- [ ] DNS records configured
- [ ] SSL certificate active
- [ ] HTTPS enforced
- [ ] www.chasemycareer.com accessible

**Post-Deployment:**
- [ ] Manual testing completed
- [ ] User registration working
- [ ] OAuth flows working
- [ ] Database operations working
- [ ] File uploads working (Supabase)
- [ ] Admin dashboard accessible
- [ ] Performance acceptable (<3s load time)
- [ ] Monitoring configured
- [ ] Backup strategy implemented

---

## 11. Frontend Structure

### 11.1 Page Routes

**Public Routes:**
- `/` - Landing page with login/signup options
- `/login` - Login page (email/password + OAuth buttons)
- `/signup` - Registration page
- `/auth/google/callback` - Google OAuth callback
- `/auth/linkedin/callback` - LinkedIn OAuth callback

**User Routes (Protected):**
- `/dashboard` - User dashboard with 50-day calendar
- `/applications` - Job applications tracker
- `/resume` - Resume builder
- `/cover-letter` - Cover letter generator
- `/profile` - User profile settings

**Admin Routes (Protected, role=admin):**
- `/admin/dashboard` - Admin overview
- `/admin/users` - User management
- `/admin/messages` - Messaging system
- `/admin/analytics` - Platform analytics

### 11.2 Component Structure

**Authentication Components:**
- LoginForm
- SignupForm
- OAuthButtons (Google, LinkedIn)

**User Dashboard Components:**
- DayCalendar (50-day grid)
- TaskCard (individual day card)
- ProgressBar
- ApplicationList
- ApplicationForm
- ResumeBuilder
- CoverLetterBuilder

**Admin Dashboard Components:**
- StatsOverview
- UserTable
- UserDetailModal
- MessageComposer
- AnalyticsCharts

---

## 12. Security Considerations

### 12.1 Authentication Security
- Passwords hashed with bcrypt (salt rounds: 10)
- JWT tokens with expiration (24 hours)
- Secure token storage (httpOnly cookies recommended)
- OAuth state parameter validation

### 12.2 Authorization
- Role-based access control (user/admin)
- Middleware validates JWT on protected routes
- Admin routes require role=admin
- Users can only access their own data

### 12.3 Data Protection
- Input validation on all API endpoints
- SQL injection prevention (prepared statements)
- XSS protection (sanitize user inputs)
- CORS configuration for frontend domain

---

## 13. Monitoring & Maintenance

### 13.1 Application Monitoring

**Cloudflare Analytics:**
- Monitor Workers requests
- Track error rates
- Analyze response times
- View geographic distribution

**Supabase Monitoring:**
- Database query performance
- Storage usage
- API request logs

**Setup Sentry for Error Tracking:**
```bash
npm install @sentry/browser @sentry/tracing
```

Add to application:
```typescript
import * as Sentry from '@sentry/browser';

Sentry.init({
  dsn: 'your-sentry-dsn',
  environment: process.env.ENVIRONMENT,
  tracesSampleRate: 1.0
});
```

### 13.2 Database Maintenance

**Regular Backups:**
```bash
# Backup D1 database
npx wrangler d1 backup create chasemycareer-db-production

# List backups
npx wrangler d1 backup list chasemycareer-db-production

# Restore from backup
npx wrangler d1 backup restore chasemycareer-db-production <backup-id>
```

**Supabase Backups:**
- Automatic daily backups (enabled by default)
- Manual backups via Supabase dashboard
- Point-in-time recovery available

### 13.3 Performance Optimization

**Caching Strategy:**
- Implement Cloudflare Cache API for static assets
- Cache user dashboard data (5 minutes TTL)
- Cache admin statistics (15 minutes TTL)

**Database Optimization:**
- Add indexes on frequently queried columns
- Optimize complex queries
- Implement pagination for large datasets

---

## 14. Future Enhancements

### 14.1 Planned Features
- Email notifications for task reminders
- Mobile app (React Native)
- AI-powered resume suggestions
- Interview scheduling integration
- Salary comparison tool
- Job matching algorithm
- Community forum
- Mentorship program

### 14.2 Scalability Considerations
- Implement caching for frequently accessed data
- Add rate limiting to prevent abuse
- Consider database sharding for large user base
- Implement CDN for static assets
- Add monitoring and logging (Sentry, LogDNA)

---

## 15. Support & Documentation

### 15.1 User Documentation
- Create user guide for 50-day program
- Video tutorials for key features
- FAQ section
- Troubleshooting guide

### 15.2 Developer Documentation
- API documentation (OpenAPI/Swagger)
- Database schema documentation
- Deployment runbook
- Contributing guidelines

### 15.3 Support Channels
- Email support: support@chasemycareer.com
- In-app chat support
- Community forum
- GitHub issues (for bugs)

---

## 16. Documentation Organization

All project documentation should be organized in a `docs/` folder with numbered files based on modification date:

**docs/ folder structure:**
```
docs/
 1.Requirement1.md
 2.Requirement2.md
 3.Branding.md
 4.TechnicalSpecs.md
 5.APIDocumentation.md
 6.DatabaseSchema.md
 7.DeploymentGuide.md
 8.TestingProcedures.md
 9.UserGuide.md
 10.ChangeLog.md
```

**Naming Convention:**
- Format: `[Number].[DocumentName].md`
- Number based on creation/modification date
- Descriptive document names
- All documents in Markdown format

**Version Control:**
- Each document update increments version number in header
- Change log maintained in separate file
- Git commits reference document numbers

---

## Appendix A: Quick Reference Commands

**Development:**
```bash
npx wrangler dev                    # Start local development
npm run test:unit                   # Run unit tests
npm run test:integration            # Run integration tests
npm run lint                        # Lint code
npm run build                       # Build project
```

**Database:**
```bash
npx wrangler d1 execute DB --local --file=schema.sql    # Initialize local DB
npx wrangler d1 execute DB --remote --file=schema.sql   # Initialize remote DB
npx wrangler d1 execute DB --local --command=\"SELECT * FROM users\"  # Query local DB
```

**Deployment:**
```bash
npx wrangler deploy --env staging       # Deploy to staging
npx wrangler deploy --env production    # Deploy to production
vercel --prod                           # Deploy frontend to Vercel
```

**Secrets Management:**
```bash
wrangler secret put SECRET_NAME --env production    # Add secret
wrangler secret list --env production               # List secrets
wrangler secret delete SECRET_NAME --env production # Delete secret
```

---

## Appendix B: Troubleshooting Guide

**Issue: Database connection fails**
- Verify database_id in wrangler.jsonc
- Check database exists: `wrangler d1 list`
- Ensure schema is initialized

**Issue: OAuth not working**
- Verify OAuth credentials in environment variables
- Check redirect URIs match in OAuth provider settings
- Ensure callback routes are correctly configured

**Issue: Tests failing**
- Verify test database is initialized
- Check environment variables for tests
- Ensure local development server is running for integration tests

**Issue: Deployment fails**
- Verify Cloudflare API token has correct permissions
- Check wrangler.jsonc configuration
- Ensure all secrets are set

**Issue: Domain not resolving**
- Verify nameservers are updated
- Check DNS records in Cloudflare
- Wait for DNS propagation (up to 24 hours)
- Use `dig` or `nslookup` to verify DNS

---

## Appendix C: Environment Variables Reference

**Required for Backend (Cloudflare Workers):**
- `JWT_SECRET`: Secret key for JWT token generation
- `GOOGLE_CLIENT_ID`: Google OAuth client ID
- `GOOGLE_CLIENT_SECRET`: Google OAuth client secret
- `LINKEDIN_CLIENT_ID`: LinkedIn OAuth client ID
- `LINKEDIN_CLIENT_SECRET`: LinkedIn OAuth client secret
- `SUPABASE_URL`: Supabase project URL
- `SUPABASE_KEY`: Supabase anon/public key
- `SUPABASE_SERVICE_KEY`: Supabase service role key

**Required for Frontend:**
- `VITE_API_URL`: Backend API URL (Cloudflare Workers URL)
- `VITE_SUPABASE_URL`: Supabase project URL
- `VITE_SUPABASE_KEY`: Supabase anon/public key

**Optional:**
- `SENTRY_DSN`: Sentry error tracking DSN
- `SLACK_WEBHOOK`: Slack webhook for notifications
- `ENVIRONMENT`: Environment name (staging/production)